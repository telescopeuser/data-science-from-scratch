{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# KudosData.com\n",
    "###############\n",
    "#\n",
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import math, random, csv, json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "######\n",
    "#\n",
    "# BOOKS ABOUT DATA\n",
    "#\n",
    "######\n",
    "\n",
    "def is_video(td):\n",
    "    \"\"\"it's a video if it has exactly one pricelabel, and if\n",
    "    the stripped text inside that pricelabel starts with 'Video'\"\"\"\n",
    "    pricelabels = td('span', 'pricelabel')\n",
    "    return (len(pricelabels) == 1 and\n",
    "            pricelabels[0].text.strip().startswith(\"Video\"))\n",
    "\n",
    "def book_info(td):\n",
    "    \"\"\"given a BeautifulSoup <td> Tag representing a book,\n",
    "    extract the book's details and return a dict\"\"\"\n",
    "    \n",
    "    title = td.find(\"div\", \"thumbheader\").a.text\n",
    "    by_author = td.find('div', 'AuthorName').text\n",
    "    authors = [x.strip() for x in re.sub(\"^By \", \"\", by_author).split(\",\")]\n",
    "    isbn_link = td.find(\"div\", \"thumbheader\").a.get(\"href\")\n",
    "    isbn = re.match(\"/product/(.*)\\.do\", isbn_link).groups()[0]\n",
    "    date = td.find(\"span\", \"directorydate\").text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"title\" : title,\n",
    "        \"authors\" : authors,\n",
    "        \"isbn\" : isbn,\n",
    "        \"date\" : date\n",
    "    }\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def scrape(num_pages=31):\n",
    "    base_url = \"http://shop.oreilly.com/category/browse-subjects/\" + \\\n",
    "           \"data.do?sortby=publicationDate&page=\"\n",
    "\n",
    "    books = []\n",
    "\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        print \"souping page\", page_num\n",
    "        url = base_url + str(page_num)\n",
    "        soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "            \n",
    "        for td in soup('td', 'thumbtext'):\n",
    "            if not is_video(td):\n",
    "                books.append(book_info(td))\n",
    "\n",
    "        # now be a good citizen and respect the robots.txt!\n",
    "        sleep(30)\n",
    "\n",
    "    return books\n",
    "\n",
    "def get_year(book):\n",
    "    \"\"\"book[\"date\"] looks like 'November 2014' so we need to \n",
    "    split on the space and then take the second piece\"\"\"\n",
    "    return int(book[\"date\"].split()[1])\n",
    "\n",
    "def plot_years(plt, books):\n",
    "    # 2014 is the last complete year of data (when I ran this)\n",
    "    year_counts = Counter(get_year(book) for book in books\n",
    "                          if get_year(book) <= 2014)\n",
    "\n",
    "    years = sorted(year_counts)\n",
    "    book_counts = [year_counts[year] for year in x]\n",
    "    plt.bar([x - 0.5 for x in years], book_counts)\n",
    "    plt.xlabel(\"year\")\n",
    "    plt.ylabel(\"# of data books\")\n",
    "    plt.title(\"Data is Big!\")\n",
    "    plt.show()\n",
    "\n",
    "##\n",
    "# \n",
    "# APIs\n",
    "#\n",
    "##\n",
    "\n",
    "endpoint = \"https://api.github.com/users/joelgrus/repos\"\n",
    "\n",
    "repos = json.loads(requests.get(endpoint).text)\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)\n",
    "\n",
    "####\n",
    "#\n",
    "# Twitter\n",
    "#\n",
    "####\n",
    "\n",
    "from twython import Twython\n",
    "\n",
    "# fill these in if you want to use the code\n",
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\"\n",
    "\n",
    "def call_twitter_search_api():\n",
    "\n",
    "    twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    # search for tweets containing the phrase \"data science\"\n",
    "    for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "        user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "        text = status[\"text\"].encode('utf-8')\n",
    "        print user, \":\", text\n",
    "        print\n",
    "\n",
    "from twython import TwythonStreamer\n",
    "\n",
    "# appending data to a global variable is pretty poor form\n",
    "# but it makes the example much simpler\n",
    "tweets = [] \n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    \"\"\"our own subclass of TwythonStreamer that specifies\n",
    "    how to interact with the stream\"\"\"\n",
    "\n",
    "    def on_success(self, data):\n",
    "        \"\"\"what do we do when twitter sends us data?\n",
    "        here data will be a Python object representing a tweet\"\"\"\n",
    "\n",
    "        # only want to collect English-language tweets\n",
    "        if data['lang'] == 'en':\n",
    "            tweets.append(data)\n",
    "\n",
    "        # stop when we've collected enough\n",
    "        if len(tweets) >= 1000:\n",
    "            self.disconnect()\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "        print status_code, data\n",
    "        self.disconnect()\n",
    "\n",
    "def call_twitter_streaming_api():\n",
    "    stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET, \n",
    "                        ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "    # starts consuming public statuses that contain the keyword 'data'\n",
    "    stream.statuses.filter(track='data')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab delimited stock prices:\n",
      "6/20/2014 AAPL 90.91\n",
      "6/20/2014 MSFT 41.68\n",
      "6/20/2014 FB 64.5\n",
      "6/19/2014 AAPL 91.86\n",
      "6/19/2014 MSFT 41.51\n",
      "6/19/2014 FB 64.34\n",
      "\n",
      "colon delimited stock prices:\n",
      "6/20/2014 AAPL 90.91\n",
      "6/20/2014 MSFT 41.68\n",
      "6/20/2014 FB 64.5\n",
      "\n",
      "writing out comma_delimited_stock_prices.txt\n",
      "BeautifulSoup\n",
      "<!DOCTYPE doctype html>\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<title>Example Domain</title>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "<style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 50px;\n",
      "        background-color: #fff;\n",
      "        border-radius: 1em;\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        body {\n",
      "            background-color: #fff;\n",
      "        }\n",
      "        div {\n",
      "            width: auto;\n",
      "            margin: 0 auto;\n",
      "            border-radius: 0;\n",
      "            padding: 1em;\n",
      "        }\n",
      "    }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "<div>\n",
      "<h1>Example Domain</h1>\n",
      "<p>This domain is established to be used for illustrative examples in documents. You may use this\n",
      "    domain in examples without prior coordination or asking for permission.</p>\n",
      "<p><a href=\"http://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "parsing json\n",
      "{u'publicationYear': 2014, u'author': u'Joel Grus', u'topics': [u'data', u'science', u'data science'], u'title': u'Data Science Book'}\n",
      "\n",
      "GitHub API\n",
      "dates [datetime.datetime(2013, 7, 5, 2, 2, 28, tzinfo=tzutc()), datetime.datetime(2013, 11, 15, 5, 33, 22, tzinfo=tzutc()), datetime.datetime(2012, 9, 18, 4, 20, 23, tzinfo=tzutc()), datetime.datetime(2016, 7, 19, 17, 34, 31, tzinfo=tzutc()), datetime.datetime(2015, 11, 11, 14, 15, 36, tzinfo=tzutc()), datetime.datetime(2016, 5, 31, 14, 33, 6, tzinfo=tzutc()), datetime.datetime(2015, 6, 30, 0, 33, 3, tzinfo=tzutc()), datetime.datetime(2013, 8, 21, 13, 26, 5, tzinfo=tzutc()), datetime.datetime(2013, 8, 18, 5, 3, 41, tzinfo=tzutc()), datetime.datetime(2015, 7, 30, 1, 54, 55, tzinfo=tzutc()), datetime.datetime(2014, 11, 9, 2, 31, 24, tzinfo=tzutc()), datetime.datetime(2013, 11, 10, 6, 52, 56, tzinfo=tzutc()), datetime.datetime(2015, 4, 8, 1, 1, 47, tzinfo=tzutc()), datetime.datetime(2016, 1, 8, 3, 33, 58, tzinfo=tzutc()), datetime.datetime(2016, 1, 21, 6, 46, 49, tzinfo=tzutc()), datetime.datetime(2013, 7, 1, 3, 36, 23, tzinfo=tzutc()), datetime.datetime(2013, 2, 22, 0, 12, 38, tzinfo=tzutc()), datetime.datetime(2016, 5, 21, 23, 57, 23, tzinfo=tzutc()), datetime.datetime(2015, 7, 2, 21, 47, 55, tzinfo=tzutc()), datetime.datetime(2012, 2, 15, 4, 55, 49, tzinfo=tzutc()), datetime.datetime(2016, 7, 11, 15, 48, 39, tzinfo=tzutc()), datetime.datetime(2016, 1, 20, 15, 28, 1, tzinfo=tzutc()), datetime.datetime(2013, 7, 4, 17, 28, 29, tzinfo=tzutc()), datetime.datetime(2013, 12, 8, 17, 53, 7, tzinfo=tzutc()), datetime.datetime(2015, 12, 28, 16, 54, 15, tzinfo=tzutc()), datetime.datetime(2015, 6, 23, 0, 27, 55, tzinfo=tzutc()), datetime.datetime(2015, 5, 23, 15, 50, 14, tzinfo=tzutc()), datetime.datetime(2013, 5, 21, 2, 51, 36, tzinfo=tzutc()), datetime.datetime(2015, 7, 18, 1, 1, 20, tzinfo=tzutc()), datetime.datetime(2016, 1, 3, 3, 20, 20, tzinfo=tzutc())]\n",
      "month_counts Counter({7: 8, 1: 4, 5: 4, 11: 4, 2: 2, 6: 2, 8: 2, 12: 2, 4: 1, 9: 1})\n",
      "weekday_count Counter({1: 6, 2: 5, 6: 5, 3: 4, 4: 4, 0: 3, 5: 3})\n",
      "last five languages [u'Python', u'Jupyter Notebook', u'Python', u'Python', u'JavaScript']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    def process(date, symbol, price):\n",
    "        print date, symbol, price\n",
    "\n",
    "    print \"tab delimited stock prices:\"\n",
    "\n",
    "    with open('tab_delimited_stock_prices.txt', 'rb') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            date = row[0]\n",
    "            symbol = row[1]\n",
    "            closing_price = float(row[2])\n",
    "            process(date, symbol, closing_price)\n",
    "\n",
    "    print\n",
    "\n",
    "    print \"colon delimited stock prices:\"\n",
    "\n",
    "    with open('colon_delimited_stock_prices.txt', 'rb') as f:\n",
    "        reader = csv.DictReader(f, delimiter=':')\n",
    "        for row in reader:\n",
    "            date = row[\"date\"]\n",
    "            symbol = row[\"symbol\"]\n",
    "            closing_price = float(row[\"closing_price\"])\n",
    "            process(date, symbol, closing_price)\n",
    "\n",
    "    print\n",
    "\n",
    "    print \"writing out comma_delimited_stock_prices.txt\"\n",
    "\n",
    "    today_prices = { 'AAPL' : 90.91, 'MSFT' : 41.68, 'FB' : 64.5 }\n",
    "\n",
    "    with open('comma_delimited_stock_prices.txt','wb') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for stock, price in today_prices.items():\n",
    "            writer.writerow([stock, price])\n",
    "\n",
    "    print \"BeautifulSoup\"\n",
    "    html = requests.get(\"http://www.example.com\").text\n",
    "#     soup = BeautifulSoup(html)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    print soup\n",
    "    print\n",
    "\n",
    "    print \"parsing json\"\n",
    "\n",
    "    serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "                      \"author\" : \"Joel Grus\",\n",
    "                      \"publicationYear\" : 2014,\n",
    "                      \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "\n",
    "    # parse the JSON to create a Python object\n",
    "    deserialized = json.loads(serialized)\n",
    "    if \"data science\" in deserialized[\"topics\"]:\n",
    "        print deserialized \n",
    "\n",
    "    print\n",
    "\n",
    "    print \"GitHub API\"\n",
    "    print \"dates\", dates\n",
    "    print \"month_counts\", month_counts\n",
    "    print \"weekday_count\", weekday_counts\n",
    "\n",
    "    last_5_repositories = sorted(repos,\n",
    "                                 key=lambda r: r[\"created_at\"],\n",
    "                                 reverse=True)[:5]\n",
    "\n",
    "    print \"last five languages\", [repo[\"language\"] \n",
    "                                  for repo in last_5_repositories]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
